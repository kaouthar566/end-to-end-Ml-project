import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import confusion_matrix, classification_report, precision_recall_curve
import warnings
warnings.filterwarnings("ignore")

# Configuration de la page
st.set_page_config(page_title="Loan Default Prediction", layout="wide")

# Titre principal
st.title("üìä Loan Default Prediction")
st.markdown("""
## **Pr√©diction du d√©faut de remboursement de pr√™t**
Cette application utilise le machine learning pour pr√©dire si un client est susceptible de faire d√©faut sur son pr√™t.
""")

# Sidebar
st.sidebar.header("Configuration")
st.sidebar.markdown("Configurez les param√®tres du mod√®le et explorez les donn√©es.")

# Chargement des donn√©es
@st.cache_data
def load_data():
    data = pd.read_csv("loan_default_dataset.csv")
    return data.copy()

try:
    loan_default_dataset = load_data()
    
    # Affichage des donn√©es brutes
    if st.sidebar.checkbox("Afficher les donn√©es brutes"):
        st.subheader("Donn√©es brutes")
        st.write(loan_default_dataset)
        
        # Statistiques de base
        st.subheader("Statistiques descriptives")
        st.write(loan_default_dataset.describe())
        
        # Informations sur les donn√©es manquantes
        st.subheader("Donn√©es manquantes")
        missing_data = loan_default_dataset.isnull().sum()
        missing_percent = (loan_default_dataset.isnull().sum() / loan_default_dataset.shape[0] * 100)
        missing_df = pd.DataFrame({
            'Valeurs manquantes': missing_data,
            'Pourcentage (%)': missing_percent
        })
        st.write(missing_df)

except FileNotFoundError:
    st.error("Le fichier 'loan_default_dataset.csv' n'a pas √©t√© trouv√©. Veuillez vous assurer qu'il est dans le m√™me r√©pertoire que cette application.")
    st.stop()

# Analyse exploratoire
st.sidebar.header("Analyse Exploratoire")

if st.sidebar.checkbox("Afficher l'analyse exploratoire"):
    st.header("üîç Analyse Exploratoire des Donn√©es")
    
    # Distribution de la variable cible
    st.subheader("Distribution de la variable cible (BAD)")
    fig, ax = plt.subplots(1, 2, figsize=(15, 5))
    
    # Diagramme en barres
    target_counts = loan_default_dataset['BAD'].value_counts()
    ax[0].bar(['Non D√©faillant (0)', 'D√©faillant (1)'], target_counts.values, color=['lightblue', 'salmon'])
    ax[0].set_title('Distribution des D√©faillants')
    ax[0].set_ylabel('Nombre de clients')
    
    # Ajout des pourcentages
    for i, v in enumerate(target_counts.values):
        ax[0].text(i, v + 10, f'{v}\n({v/len(loan_default_dataset)*100:.1f}%)', 
                   ha='center', va='bottom')
    
    # Camembert
    ax[1].pie(target_counts.values, labels=['Non D√©faillant', 'D√©faillant'], 
              autopct='%1.1f%%', colors=['lightblue', 'salmon'])
    ax[1].set_title('R√©partition des D√©faillants')
    
    st.pyplot(fig)
    
    # Variables cat√©gorielles
    st.subheader("Variables Cat√©gorielles")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.write("**R√©partition par RAISON du pr√™t:**")
        reason_counts = loan_default_dataset['REASON'].value_counts()
        fig, ax = plt.subplots()
        ax.pie(reason_counts.values, labels=reason_counts.index, autopct='%1.1f%%')
        st.pyplot(fig)
    
    with col2:
        st.write("**R√©partition par TYPE d'emploi:**")
        job_counts = loan_default_dataset['JOB'].value_counts()
        fig, ax = plt.subplots()
        ax.pie(job_counts.values, labels=job_counts.index, autopct='%1.1f%%')
        st.pyplot(fig)

# Pr√©traitement des donn√©es
st.sidebar.header("Pr√©traitement des Donn√©es")

def preprocess_data(df, fit_mode=True, feature_columns=None):
    # Copie des donn√©es
    data = df.copy()
    
    # Conversion des types
    categorical_cols = ['REASON', 'JOB', 'BAD']
    for col in categorical_cols:
        if col in data.columns:
            data[col] = data[col].astype("category")
    
    # Gestion des valeurs manquantes (exemple simplifi√©)
    numerical_cols = ['LOAN', 'MORTDUE', 'VALUE', 'YOJ', 'DEROG', 'DELINQ', 'CLAGE', 'NINQ', 'CLNO', 'DEBTINC']
    
    for col in numerical_cols:
        if col in data.columns:
            data[col].fillna(data[col].median(), inplace=True)
    
    # Encodage des variables cat√©gorielles
    if fit_mode:
        # Mode entra√Ænement - cr√©er les dummy variables
        data = pd.get_dummies(data, columns=['REASON', 'JOB'], drop_first=True)
        # Sauvegarder les colonnes pour la pr√©diction
        st.session_state['feature_columns'] = data.drop('BAD', axis=1).columns.tolist()
    else:
        # Mode pr√©diction - utiliser les m√™mes colonnes que lors de l'entra√Ænement
        data = pd.get_dummies(data, columns=['REASON', 'JOB'], drop_first=False)
        
        # S'assurer que nous avons toutes les colonnes n√©cessaires
        if feature_columns is not None:
            # Ajouter les colonnes manquantes avec des valeurs 0
            for col in feature_columns:
                if col not in data.columns:
                    data[col] = 0
            
            # R√©organiser les colonnes dans le m√™me ordre
            data = data[feature_columns + ['BAD'] if 'BAD' in data.columns else feature_columns]
    
    return data

if st.sidebar.checkbox("Afficher les donn√©es apr√®s pr√©traitement"):
    st.header("üîÑ Donn√©es apr√®s Pr√©traitement")
    processed_data = preprocess_data(loan_default_dataset)
    st.write("Forme des donn√©es apr√®s pr√©traitement:", processed_data.shape)
    st.write(processed_data.head())

# Mod√©lisation
st.sidebar.header("Mod√©lisation")

# S√©lection du mod√®le
model_choice = st.sidebar.selectbox(
    "Choisissez le mod√®le de pr√©diction:",
    ["For√™t Al√©atoire", "R√©gression Logistique", "Arbre de D√©cision"],
    index=0
)

# Param√®tres du mod√®le selon le choix
if model_choice == "Arbre de D√©cision":
    max_depth = st.sidebar.slider("Profondeur maximale de l'arbre", 1, 20, 10)
    min_samples_split = st.sidebar.slider("√âchantillons minimum pour diviser", 2, 20, 2)

def train_model(data, model_type="For√™t Al√©atoire"):
    # Pr√©paration des donn√©es
    X = data.drop('BAD', axis=1)
    y = data['BAD']
    
    # S√©paration train/test
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)
    
    # Normalisation
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
    # S√©lection et entra√Ænement du mod√®le
    if model_type == "For√™t Al√©atoire":
        model = RandomForestClassifier(n_estimators=100, random_state=42)
    elif model_type == "R√©gression Logistique":
        model = LogisticRegression(random_state=42, max_iter=1000)
    elif model_type == "Arbre de D√©cision":
        model = DecisionTreeClassifier(
            max_depth=max_depth,
            min_samples_split=min_samples_split,
            random_state=42
        )
    else:
        model = RandomForestClassifier(n_estimators=100, random_state=42)
    
    model.fit(X_train_scaled, y_train)
    
    return model, X_test_scaled, y_test, scaler, X_train_scaled, y_train, X.columns.tolist()

if st.sidebar.checkbox("Entra√Æner le mod√®le"):
    st.header("ü§ñ Mod√®le de Pr√©diction")
    st.write(f"**Mod√®le s√©lectionn√© :** {model_choice}")
    
    with st.spinner(f"Entra√Ænement du mod√®le {model_choice} en cours..."):
        processed_data = preprocess_data(loan_default_dataset, fit_mode=True)
        model, X_test, y_test, scaler, X_train, y_train, feature_names = train_model(processed_data, model_choice)
        
        # √âvaluation du mod√®le
        y_pred = model.predict(X_test)
        
        st.subheader("Performance du Mod√®le")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.write("**Rapport de Classification:**")
            report = classification_report(y_test, y_pred, output_dict=True)
            report_df = pd.DataFrame(report).transpose()
            st.dataframe(report_df)
        
        with col2:
            st.write("**Matrice de Confusion:**")
            cm = confusion_matrix(y_test, y_pred)
            fig, ax = plt.subplots()
            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax)
            ax.set_xlabel('Pr√©dit')
            ax.set_ylabel('R√©el')
            ax.set_title('Matrice de Confusion')
            st.pyplot(fig)
        
        # Stocker le mod√®le et les informations dans la session
        st.session_state['trained_model'] = model
        st.session_state['scaler'] = scaler
        st.session_state['model_trained'] = True
        st.session_state['model_type'] = model_choice
        st.session_state['feature_names'] = feature_names
        
        st.success("Mod√®le entra√Æn√© avec succ√®s!")

# Pr√©diction en temps r√©el
st.sidebar.header("Pr√©diction")

st.header("üéØ Pr√©dire le Risque de D√©faut")

# Afficher le mod√®le s√©lectionn√©
if 'model_trained' in st.session_state and st.session_state['model_trained']:
    st.write(f"**Mod√®le utilis√© pour la pr√©diction :** {st.session_state['model_type']}")
else:
    st.warning("Veuillez d'abord entra√Æner un mod√®le en cochant 'Entra√Æner le mod√®le' dans la sidebar.")

# Formulaire de saisie
st.subheader("Saisissez les informations du client:")

col1, col2, col3 = st.columns(3)

with col1:
    loan_amount = st.number_input("Montant du pr√™t (LOAN)", min_value=0, value=10000)
    mortdue = st.number_input("Montant hypoth√©caire (MORTDUE)", min_value=0, value=50000)
    property_value = st.number_input("Valeur du bien (VALUE)", min_value=0, value=75000)

with col2:
    job = st.selectbox("Type d'emploi (JOB)", ['Other', 'Office', 'ProfExe', 'Mgr', 'Self', 'Sales'])
    years_job = st.number_input("Ann√©es dans l'emploi (YOJ)", min_value=0.0, value=5.0)
    derogatory_reports = st.number_input("Rapports d√©rogatoires (DEROG)", min_value=0, value=0)

with col3:
    delinquent = st.number_input("D√©linquants (DELINQ)", min_value=0, value=0)
    credit_age = st.number_input("√Çge du cr√©dit (CLAGE)", min_value=0.0, value=150.0)
    recent_inquiries = st.number_input("Demandes r√©centes (NINQ)", min_value=0, value=1)

reason = st.selectbox("Raison du pr√™t", ['HomeImp', 'DebtCon'])
credit_lines = st.number_input("Lignes de cr√©dit (CLNO)", min_value=0, value=20)
debt_income_ratio = st.number_input("Ratio dette/revenu (DEBTINC)", min_value=0.0, value=35.0)

if st.button("Pr√©dire le risque"):
    # V√©rifier si un mod√®le est entra√Æn√©
    if 'model_trained' not in st.session_state or not st.session_state['model_trained']:
        st.error("Veuillez d'abord entra√Æner un mod√®le en cochant 'Entra√Æner le mod√®le' dans la sidebar.")
    else:
        try:
            # Pr√©paration des donn√©es pour la pr√©diction
            input_data = {
                'LOAN': loan_amount,
                'MORTDUE': mortdue,
                'VALUE': property_value,
                'YOJ': years_job,
                'DEROG': derogatory_reports,
                'DELINQ': delinquent,
                'CLAGE': credit_age,
                'NINQ': recent_inquiries,
                'CLNO': credit_lines,
                'DEBTINC': debt_income_ratio,
                'REASON': reason,
                'JOB': job
            }
            
            # Conversion en DataFrame
            input_df = pd.DataFrame([input_data])
            
            # Pr√©traiter les donn√©es de la m√™me mani√®re que lors de l'entra√Ænement
            input_processed = preprocess_data(input_df, fit_mode=False, feature_columns=st.session_state['feature_names'])
            
            # Supprimer BAD s'il existe (pour la pr√©diction)
            if 'BAD' in input_processed.columns:
                input_processed = input_processed.drop('BAD', axis=1)
            
            # S'assurer que toutes les colonnes sont pr√©sentes et dans le bon ordre
            missing_cols = set(st.session_state['feature_names']) - set(input_processed.columns)
            for col in missing_cols:
                input_processed[col] = 0
            
            # R√©organiser les colonnes
            input_processed = input_processed[st.session_state['feature_names']]
            
            # Standardisation des donn√©es
            input_scaled = st.session_state['scaler'].transform(input_processed)
            
            # Pr√©diction avec le mod√®le entra√Æn√©
            model = st.session_state['trained_model']
            risk_probability = model.predict_proba(input_scaled)[0][1]
            
            st.subheader("R√©sultat de la Pr√©diction")
            
            if risk_probability < 0.3:
                st.success(f"‚úÖ **FAIBLE RISQUE** - Probabilit√© de d√©faut: {risk_probability:.1%}")
                st.info("Recommandation: Pr√™t approuv√©")
            elif risk_probability < 0.6:
                st.warning(f"‚ö†Ô∏è **RISQUE MOD√âR√â** - Probabilit√© de d√©faut: {risk_probability:.1%}")
                st.info("Recommandation: Analyse suppl√©mentaire recommand√©e")
            else:
                st.error(f"üö® **HAUT RISQUE** - Probabilit√© de d√©faut: {risk_probability:.1%}")
                st.info("Recommandation: Pr√™t non recommand√©")
            
            # Afficher des informations suppl√©mentaires selon le mod√®le
            st.write(f"**Mod√®le utilis√© :** {st.session_state['model_type']}")
            
            # Graphique de la probabilit√©
            fig, ax = plt.subplots(figsize=(8, 2))
            ax.barh(['Probabilit√© de d√©faut'], [risk_probability], color='salmon', alpha=0.7)
            ax.barh(['Probabilit√© de remboursement'], [1-risk_probability], color='lightgreen', alpha=0.7)
            ax.set_xlim(0, 1)
            ax.set_xlabel('Probabilit√©')
            ax.set_title('Distribution des Probabilit√©s de Pr√©diction')
            st.pyplot(fig)
            
        except Exception as e:
            st.error(f"Erreur lors de la pr√©diction: {str(e)}")
            st.info("Assurez-vous que le mod√®le a √©t√© correctement entra√Æn√© et que toutes les colonnes n√©cessaires sont pr√©sentes.")

# Footer
st.markdown("---")
st.markdown("""
### **Recommandations pour la banque:**
- Surveiller particuli√®rement le ratio dette/revenu (DEBTINC)
- Accorder une attention aux ant√©c√©dents de cr√©dit (DEROG, DELINQ)
- Consid√©rer la stabilit√© professionnelle (YOJ)
- Analyser le motif du pr√™t (HomeImp vs DebtCon)
""")

# Fonctionnalit√©s suppl√©mentaires
st.sidebar.header("Fonctionnalit√©s Avanc√©es")
if st.sidebar.checkbox("Afficher l'importance des caract√©ristiques"):
    st.header("üìà Importance des Caract√©ristiques")
    
    # V√©rifier si un mod√®le est entra√Æn√©
    if 'model_trained' not in st.session_state or not st.session_state['model_trained']:
        st.warning("Veuillez d'abord entra√Æner un mod√®le pour voir l'importance des caract√©ristiques.")
    else:
        model = st.session_state['trained_model']
        model_type = st.session_state['model_type']
        
        # Pr√©parer les noms de caract√©ristiques
        feature_names = st.session_state['feature_names']
        
        # Obtenir l'importance des caract√©ristiques selon le mod√®le
        if model_type == "For√™t Al√©atoire" or model_type == "Arbre de D√©cision":
            if hasattr(model, 'feature_importances_'):
                importance = model.feature_importances_
                
                # Cr√©er un DataFrame pour l'importance
                feature_importance_df = pd.DataFrame({
                    'feature': feature_names,
                    'importance': importance
                }).sort_values('importance', ascending=True)
                
                # Tracer le graphique
                fig, ax = plt.subplots(figsize=(10, 8))
                y_pos = np.arange(len(feature_importance_df))
                ax.barh(y_pos, feature_importance_df['importance'], color='skyblue')
                ax.set_yticks(y_pos)
                ax.set_yticklabels(feature_importance_df['feature'])
                ax.set_xlabel('Importance')
                ax.set_title(f'Importance des Caract√©ristiques ({model_type})')
                plt.tight_layout()
                st.pyplot(fig)
                
                # Afficher le tableau des importances
                st.write("**Valeurs d'importance d√©taill√©es:**")
                st.dataframe(feature_importance_df.sort_values('importance', ascending=False))
            else:
                st.info("L'importance des caract√©ristiques n'est pas disponible pour ce mod√®le.")
        else:
            st.info("L'importance des caract√©ristiques native n'est disponible que pour les mod√®les For√™t Al√©atoire et Arbre de D√©cision.")
            
        # Pour la r√©gression logistique, on peut afficher les coefficients
        if model_type == "R√©gression Logistique":
            if hasattr(model, 'coef_'):
                coefficients = model.coef_[0]
                
                # Cr√©er un DataFrame pour les coefficients
                coef_df = pd.DataFrame({
                    'feature': feature_names,
                    'coefficient': coefficients
                }).sort_values('coefficient', ascending=True)
                
                # Tracer le graphique
                fig, ax = plt.subplots(figsize=(10, 8))
                y_pos = np.arange(len(coef_df))
                colors = ['red' if x < 0 else 'green' for x in coef_df['coefficient']]
                ax.barh(y_pos, coef_df['coefficient'], color=colors, alpha=0.7)
                ax.set_yticks(y_pos)
                ax.set_yticklabels(coef_df['feature'])
                ax.set_xlabel('Coefficient')
                ax.set_title('Coefficients de la R√©gression Logistique')
                ax.axvline(x=0, color='black', linestyle='-', alpha=0.3)
                plt.tight_layout()
                st.pyplot(fig)
                
                # Afficher le tableau des coefficients
                st.write("**Coefficients d√©taill√©s:**")
                st.dataframe(coef_df.sort_values('coefficient', ascending=False))

# Information sur les mod√®les
st.sidebar.markdown("---")
st.sidebar.header("√Ä propos des mod√®les")
st.sidebar.markdown("""
**For√™t Al√©atoire**: Ensemble d'arbres de d√©cision, robuste et pr√©cis  
**R√©gression Logistique**: Mod√®le lin√©aire, facile √† interpr√©ter  
**Arbre de D√©cision**: Mod√®le unique, tr√®s interpr√©table
""")
